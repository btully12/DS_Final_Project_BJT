{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2fcdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import mysql\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import mysql\n",
    "from mysql.connector import MySQLConnection, Error\n",
    "import time\n",
    "from datetime import datetime, time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f019f79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "def query_with_fetchall():\n",
    "    try:\n",
    "        connection = mysql.connector.connect(user='brett', \n",
    "                                             password='BrettTully#2023',\n",
    "                                             host='r2klabs.com',\n",
    "                                             database='sensor')\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT * FROM rpisense order by sensor_date DESC;\")\n",
    "        rows = cursor.fetchall()\n",
    "        print('Total Row(s):', cursor.rowcount)\n",
    "        title = [i[0] for i in cursor.description]\n",
    "        print(title)\n",
    "        global df\n",
    "        df = pd.DataFrame(rows)\n",
    "        df['time'] = df[1].dt.time\n",
    "        df['weekday'] = df[1].dt.weekday\n",
    "        df['date'] = df[1].dt.date\n",
    "        #df.to_csv(\"sensordata.csv\",index=False)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "query_with_fetchall()\n",
    "\n",
    "df.rename(columns={0:\"Device\",1:\"Datetime\",2:\"Temp F\",3:\"Humidity\",\"time\":\"Time\",\"weekday\":\"Weekday\",\"date\":\"Date\"},inplace=True)        \n",
    "\n",
    "\n",
    "\n",
    "################## Creating the dictionary that contains the class times  ################################################################################\n",
    "\n",
    "\n",
    "occupied_times = {\n",
    "    \"P002\": {\n",
    "        \"0\": [(\"09:00:00\",\"09:50:00\"),(\"10:00:00\",\"10:50:00\") ,(\"13:00:00\",\"13:50:00\")],\n",
    "        \"1\": [(\"09:00:00\", \"11:00:00\"),(\"12:15:00\",\"13:30:00\")],\n",
    "        \"2\": [(\"09:00:00\",\"9:50:00\"),(\"10:00:00\",\"10:50:00\"), (\"13:00:00\",\"13:50:00\")],\n",
    "        \"3\": [(\"11:00:00\",\"12:15:00\"),(\"13:30:00\",\"15:40:00\")],\n",
    "        \"4\": [(\"09:00:00\",\"09:50:00\"),(\"10:00:00\",\"10:50:00\")]\n",
    "    },\n",
    "    \"P004\": {\n",
    "        \"0\": [(\"09:00:00\",\"09:50:00\"),(\"10:00:00\",\"10:50:00\")],\n",
    "        \"1\": [(\"08:40:00\",\"10:40:00\"),(\"12:15:00\", \"13:30:00\"), (\"13:40:00\",\"14:50:00\")],\n",
    "        \"2\": [(\"09:00:00\",\"09:50:00\"),(\"10:00:00\",\"10:50:00\")],\n",
    "        \"3\": [(\"08:40:00\",\"10:40:00\"),(\"12:15:00\", \"13:30:00\"),(\"13:40:00\",\"14:50:00\")],\n",
    "        \"4\": [(\"09:00:00\",\"09:50:00\"),(\"10:00:00\",\"10:50:00\")]\n",
    "    },\n",
    "    \"P006B\": {\n",
    "        \"1\": [(\"10:00:00\", \"12:00:00\")],\n",
    "        \"2\": [(\"10:00:00\", \"12:00:00\")],\n",
    "        \"3\": [(\"10:00:00\", \"12:00:00\")],\n",
    "        \"4\": [(\"10:00:00\", \"12:00:00\")],\n",
    "        \"5\": [(\"10:00:00\", \"12:00:00\")]\n",
    "    }\n",
    "}\n",
    "\n",
    "flattened = []\n",
    "\n",
    "\n",
    "\n",
    "# turning the dictionary into a dataframe\n",
    "\n",
    "for room, room_sessions in occupied_times.items(): \n",
    "    for dow, session_windows in room_sessions.items():\n",
    "        for session_window in session_windows: \n",
    "            flattened.append([room,dow,session_window[0],\n",
    "                             session_window[1]])\n",
    "room_times = pd.DataFrame(flattened, columns =['Device','Weekday','Start Time','End Time'])           \n",
    "room_times.to_csv('room_times.csv')\n",
    "\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "room_times = room_times.reset_index(drop=True)\n",
    "\n",
    "df = df.sample(100000)\n",
    "\n",
    "df['Time'] = df['Time'].astype(str)\n",
    "df['Device'] = df['Device'].astype(str)\n",
    "room_times['Weekday'] = room_times['Weekday'].astype('int64')\n",
    "room_times['Start Time'] = room_times['Start Time'].astype(str)\n",
    "room_times['End Time'] = room_times['End Time'].astype(str)\n",
    "room_times['Device'] = room_times['Device'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############MODEL################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb58ef",
   "metadata": {},
   "source": [
    "# Assigning a 1 or 0 based on whether the class was actually in session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1005c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Convert start_time and end_time columns to time objects\n",
    "room_times['Start Time'] = room_times['Start Time'].apply(lambda x: datetime.strptime(x, '%H:%M:%S').time())\n",
    "room_times['End Time'] = room_times['End Time'].apply(lambda x: datetime.strptime(x, '%H:%M:%S').time())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert time_stamp column to time objects and check if it falls between any of the time ranges on the specified days of the week and room numbers\n",
    "df['Time'] = df['Time'].apply(lambda x: datetime.strptime(x, '%H:%M:%S').time())\n",
    "\n",
    "# Create new columns in the time_stamps_df DataFrame called 'in_range' and 'room_number', and initialize them to 0 and None, respectively\n",
    "df['in_use'] = 0\n",
    "\n",
    "\n",
    "# Iterate through each row in the time_stamps_df DataFrame, and for each row we iterate through each row in the df DataFrame to check if the time stamp falls between any of the time ranges on the specified days of the week and room numbers. If the time stamp falls between any of the time ranges on the specified day of the week and room number, we set the value of 'in_range' to 1 and the value of 'room_number' to the corresponding room number using the at() method.\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for index2, row2 in room_times.iterrows():\n",
    "        if row2['Weekday'] == row['Weekday'] and row2['Device'] == row['Device']:\n",
    "            if row2['Start Time'] <= row['Time'] <= row2['End Time']:\n",
    "                df.at[index, 'in_use'] = 1\n",
    "                break       \n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b8b63",
   "metadata": {},
   "source": [
    "# Grid Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed65e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preprocess data\n",
    "\n",
    "\n",
    "df['Temp F'] = df['Temp F'].fillna(df['Temp F'].mean())\n",
    "\n",
    "# Split into features and target\n",
    "X = df[['Humidity', 'Temp F','Weekday']]\n",
    "y = df['in_use']\n",
    "\n",
    "# Define models and parameters\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'clf__penalty': ['l1', 'l2', 'elasticnet',None],\n",
    "            'clf__C': [0.1, 1, 10],\n",
    "            'clf__solver': ['saga', 'liblinear','lbfgs','sag','newton-cg']\n",
    "           \n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__max_depth': [None, 5, 10,15,20],\n",
    "            'clf__min_samples_leaf': [1, 2, 5]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'clf__n_estimators': [50, 100, 150,300,500],\n",
    "            'clf__max_depth': [None, 5, 10,50,100],\n",
    "            'clf__min_samples_leaf': [1, 2, 5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Perform grid search CV\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "for model_name, model_params in models.items():\n",
    "    print('Running grid search for:', model_name)\n",
    "    model_pipeline = pipeline.set_params(clf=model_params['model'])\n",
    "    grid_search = GridSearchCV(model_pipeline, model_params['params'], cv=5, scoring='accuracy',verbose=3)\n",
    "    grid_search.fit(X, y)\n",
    "    print('Best parameters:', grid_search.best_params_)\n",
    "    print('Best score:', grid_search.best_score_)\n",
    "    if grid_search.best_score_ > best_score:\n",
    "        best_score = grid_search.best_score_\n",
    "        best_model = model_name\n",
    "\n",
    "\n",
    "print('Best model:', best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ed9fb",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn heatmap\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_score = grid_search.predict_proba(X)[:, 1]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "\n",
    "# Plot the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_score)\n",
    "roc_auc = roc_auc_score(y, y_score)\n",
    "sns.lineplot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "sns.lineplot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abacca21",
   "metadata": {},
   "source": [
    "### back ups in case anything got deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abac4b0",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c9aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to your column and transform the data\n",
    "encoded_column = label_encoder.fit_transform(df['Device'])\n",
    "\n",
    "# Replace the old column with the encoded column in your dataframe\n",
    "#df['Device'] = encoded_column\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Weekday','Temp F','Humidity']], df['in_use'], test_size=0.4, random_state=42)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Get probability estimates for each class\n",
    "proba = model.predict_proba(X_test)\n",
    "\n",
    "# Get probability for positive class (in_use = 1)\n",
    "pos_proba = proba[:, 1]\n",
    "\n",
    "# Create new column in test set for predicted probability\n",
    "X_test['pred_proba'] = pos_proba\n",
    "\n",
    "# Calculate accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Add performance metrics to the dataframe\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df00ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "# Assuming your predicted labels are stored in y_pred and true labels are in y_true\n",
    "# Assuming your predicted probabilities for each class are stored in y_score\n",
    "\n",
    "y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "\n",
    "# Plot the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "sns.lineplot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "sns.lineplot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0610d9",
   "metadata": {},
   "source": [
    "# Models again, working on making predictions for the next 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f9b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "\n",
    "# Convert \"Timestamp\" column to datetime objects\n",
    "#df['Date'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "# Set \"Timestamp\" column as index\n",
    "#df = df.set_index('Datetime')\n",
    "\n",
    "df['Temp F'] = df['Temp F'].astype(float)\n",
    "df['Humidity'] = df['Humidity'].astype(float)\n",
    "df['in_use'] = df['in_use'].astype(bool)\n",
    "df.set_index(pd.DatetimeIndex(df['Datetime']), inplace=True)\n",
    "\n",
    "\n",
    "# Create a new dataframe that resamples the data at 30 minute intervals and calculates the mean of each column\n",
    "df_resampled = df.resample('30T').mean()\n",
    "\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Define the features and target variable\n",
    "X = df_resampled['Temp F']\n",
    "y = df_resampled['in_use']\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Scale the target variable if necessary\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "y = y.ravel()\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Print out the classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Create a new dataframe with predictions for the next 30 minutes\n",
    "last_time = df_resampled.index[-1]\n",
    "next_time = last_time + pd.Timedelta('30 minutes')\n",
    "next_temp = df['Temp F'].iloc[-1]\n",
    "X_next = pd.DataFrame({'Temp F': [next_temp]}, index=[next_time])\n",
    "y_next = logreg.predict(X_next)\n",
    "\n",
    "# Print out the prediction for the next 30 minutes\n",
    "print(\"Occupancy prediction for the next 30 minutes:\", y_next[0])\n",
    "\n",
    "# Create a new dataframe with predictions for the next 30 minutes at each minute\n",
    "future_times = pd.date_range(last_time, periods=31, freq='T')[1:]\n",
    "future_temps = [df['Temp F'].iloc[-1]]*30\n",
    "X_future = pd.DataFrame({'Temp F': future_temps}, index=future_times)\n",
    "y_future = logreg.predict(X_future)\n",
    "\n",
    "# Create a new dataframe with the predictions for the next 30 minutes\n",
    "df_pred = pd.DataFrame({'Datetime': future_times, 'in_use': y_future})\n",
    "\n",
    "# Print out the dataframe with predictions\n",
    "print(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c218fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to your column and transform the data\n",
    "encoded_column = label_encoder.fit_transform(df['Device'])\n",
    "\n",
    "# Replace the old column with the encoded column in your dataframe\n",
    "df['Device'] = encoded_column\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Weekday','Device','Temp F','Humidity']], df['in_use'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93abf65",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae829425",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be44e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db080ab4",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have to use a lambda function as my statistics would come in as scientific notation normally\n",
    "df[\"Temp F\"].describe().apply(lambda x: format(x, 'f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Humidity\"].describe().apply(lambda x: format(x, 'f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53007f",
   "metadata": {},
   "source": [
    "# Categorical Variable Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5dea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Device'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28321297",
   "metadata": {},
   "source": [
    "# Correlation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bd8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_table = df.corr()\n",
    "\n",
    "corr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a0006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74787d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2763f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(corr_table).set(title='Heatmap of Temp F and Humidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee5fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\n",
    "df['Weekday'] = df['Weekday'].apply(lambda x: days[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.histplot(data=df, x=\"Temp F\").set(title='Histogram of Temp F')\n",
    "plt.ylim(0,20000)\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfa3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"Humidity\").set(title='Histogram of Humidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0058695",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"Temp F\", hue=\"Device\", multiple=\"stack\").set(title='Histogram of Temp F')\n",
    "plt.ylim(0,20000)\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"Humidity\", hue=\"Device\", multiple=\"stack\").set(title='Histogram of Humidity with Hue as Device')\n",
    "plt.ylim(0,20000)\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03956b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"Humidity\", hue=\"Weekday\", multiple=\"stack\").set(title='Histogram of Humidity with Hue as Weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db02b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"Humidity\", hue=\"Device\", multiple=\"stack\").set(title='Histogram of Humidity with Hue as Device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df, x=\"Date\", y=\"Temp F\",hue='Device').set(title='Line Plot of Temp F with Hue as Device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cd7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df, x=\"Date\", y=\"Humidity\",hue='Device').set(title='Line Plot of Humidity with Hue as Device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"Temp F\", y=\"Humidity\").set(title='Scatterplot of Humidity and Temp F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"Temp F\", y=\"Humidity\").set(title='Scatterplot of Humidity and Temp F')\n",
    "plt.xlim(0,100)\n",
    "plt.ylim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef00f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.boxplot(data=df, x=\"Weekday\", y=\"Humidity\",hue=\"Device\").set(title='Boxplot of Humidity/Weekday with Hue as Device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38899b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"Weekday\", y=\"Humidity\").set(title='Boxplot of Humidity/Weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56850af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"Device\", y=\"Humidity\").set(title='Boxplot of Humidity/Device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"Device\", y=\"Humidity\",hue=\"Weekday\").set(title='Boxplot of Humidity/Device with hue as Weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"Device\", y=\"Humidity\").set(title='Boxplot of Humidity/Device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=df, kind=\"bar\",\n",
    "    x=\"Device\", y=\"Temp F\", hue=\"Weekday\",palette=\"dark\", alpha=.6, height=6).set(title='Bar Chart of Temp F/Device with hue as Weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=df, kind=\"bar\",\n",
    "    x=\"Weekday\", y=\"Temp F\", hue=\"Device\",palette=\"dark\", alpha=.6, height=6\n",
    ").set(title='Bar Chart of Temp F/Weekday with hue as Device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7eb0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=df, kind=\"bar\",\n",
    "    x=\"Weekday\", y=\"Humidity\", hue=\"Device\",palette=\"turbo\", alpha=.6, height=6).set(title='Bar Chart of Humidity/Weekday with hue as Device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d5f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=df, kind=\"bar\",\n",
    "    x=\"Device\", y=\"Humidity\", hue=\"Weekday\",palette=\"turbo\", alpha=.6, height=6\n",
    ").set(title='Bar Chart of Humidity/Device with hue as Weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e9e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9de2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
